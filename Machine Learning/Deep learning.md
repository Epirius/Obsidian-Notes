in traditional [[Neural network|neural networks]] the network was shallow (few hidden layers)
modern neural networks are typically deeper

why does deepness help?
- universal approximator theorem: even neural networks with a single hidden layer can approximate any function with arbitrary precision given enough neurons
- often having several narrow layers works better than one wide one
- the earlier layer produce simple features, and the later ones produce more complex features.
- having to many layers can lead to overfitting
